# ğŸ¤– AI Research Assistant â€” LangJu Edition  
> æœ¬åœ° + äº‘ç«¯æ··åˆ AI Agentï¼šæ”¯æŒ Ollama(Qwen2) ä¸ OpenAI(GPT) æ¨¡å‹äº’æ¢ï¼›  
> é›†æˆ RAG æ–‡æ¡£æ£€ç´¢ã€çŸ­æœŸè®°å¿†ã€å·¥å…·è°ƒç”¨ã€Streamlit å‰ç«¯ã€FastAPI APIã€Docker éƒ¨ç½²ã€‚  

A **local + cloud hybrid AI Agent** powered by **Qwen2 (Ollama)** & **GPT (OpenAI)**.  
Includes **RAG**, **memory**, **tool use**, **Streamlit UI**, **FastAPI REST API**, and **Docker** support.

---

## âš™ï¸ Tech Stack
Python 3.11 Â· smolagents Â· LangChain Â· LiteLLM Â·  
Chroma / FAISS Â· SentenceTransformers Â· Streamlit Â· FastAPI Â· Docker  

---

## ğŸš€ Run Locally (Streamlit Web UI)

```bash
# 1ï¸âƒ£ Create environment
python -m venv .venv && .\.venv\Scripts\activate   # (Windows PowerShell)

# 2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

# 3ï¸âƒ£ Run Streamlit interface
streamlit run app/main.py
ğŸ§© åŠŸèƒ½è¯´æ˜ï¼š

ğŸ“„ ä¸Šä¼  PDF / TXT / DOCX æ–‡ä»¶ â†’ è‡ªåŠ¨åˆ†å—å¹¶åµŒå…¥å‘é‡æ•°æ®åº“

ğŸ’¬ ä¾§è¾¹æ é€‰æ‹©åç«¯ï¼ˆOllama æˆ– OpenAIï¼‰

ğŸ§  å…·å¤‡è®°å¿†åŠŸèƒ½ã€ä¸Šä¸‹æ–‡æ£€ç´¢ä¸å·¥å…·è°ƒç”¨

ğŸ§© FastAPI (REST API Server)
bash
Copy code
# å¯åŠ¨ API æœåŠ¡
uvicorn app.server:app --reload --port 8000
Chat endpoint

bash
Copy code
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"prompt":"Explain RAG in one sentence","backend":"ollama"}'
Ingest a document

bash
Copy code
curl -X POST http://localhost:8000/ingest -F "file=@data/sample_docs/intro.txt"
ğŸ’¡ /chat â†’ è¾“å…¥ prompt è·å–æ™ºèƒ½å›å¤
ğŸ’¡ /ingest â†’ ä¸Šä¼ æ–‡æ¡£è‡³å‘é‡åº“ï¼ˆChroma æˆ– FAISSï¼‰

ğŸ§  RAG / Vector DB Configuration
åœ¨ app/config/settings.yaml æ–‡ä»¶ä¸­é…ç½®å‘é‡æ•°æ®åº“å‚æ•°ï¼š

yaml
Copy code
rag:
  vector_db: chroma   # å¯é€‰ï¼šchroma æˆ– faiss
  collection_name: langju_docs
  top_k: 4
è¯´æ˜ï¼š

Chroma â†’ å­˜å‚¨è·¯å¾„ï¼šdata/embeddings/chroma

FAISS â†’ å­˜å‚¨è·¯å¾„ï¼šdata/embeddings/faiss

é»˜è®¤ä½¿ç”¨ SentenceTransformers åµŒå…¥æ¨¡å‹ï¼šall-MiniLM-L6-v2

æ”¯æŒ PDFã€DOCXã€TXT æ–‡æ¡£è§£æä¸åˆ†å—ï¼ˆ900 å­—ç¬¦ / 150 é‡å ï¼‰

ğŸ” Switching Backend (Ollama â†” OpenAI)
æ¨¡å¼	åç«¯	å¯åŠ¨æ–¹å¼
æœ¬åœ°æ¨¡å‹	Ollama (Qwen2:7b)	ollama serve & â†’ ä¾§è¾¹æ é€‰æ‹© Ollama
äº‘ç«¯æ¨¡å‹	OpenAI GPT-4 / GPT-4o-mini	è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY

PowerShell è®¾ç½®ç¤ºä¾‹ï¼š

powershell
Copy code
$env:OPENAI_API_KEY = "sk-xxxxxx"
ğŸ³ Docker Deployment
bash
Copy code
# Build image
docker build -t langju/ai-agent-demo .

# Run container
docker run -p 8000:8000 -v ${PWD}/data:/app/data langju/ai-agent-demo
è¯´æ˜ï¼š

Web UI: http://localhost:8501

API: http://localhost:8000

æ•°æ®æŒä¹…åŒ–ï¼šæŒ‚è½½ data/ ç›®å½•ä¿å­˜åµŒå…¥å‘é‡

ğŸ§± Project Structure
bash
Copy code
ai-agent-demo/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py             # Streamlit Web UI
â”‚   â”œâ”€â”€ server.py           # FastAPI REST API
â”‚   â”œâ”€â”€ agent_core.py       # Agent orchestration logic
â”‚   â”œâ”€â”€ models/             # Model wrappers (Ollama/OpenAI)
â”‚   â”œâ”€â”€ memory/             # Vector store + memory modules
â”‚   â”œâ”€â”€ tools/              # Tool implementations
â”‚   â””â”€â”€ config/settings.yaml
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample_docs/
â”‚   â””â”€â”€ embeddings/
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_agent.py
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ RESUME_EN.md / RESUME_CN.md
â””â”€â”€ README.md
ğŸ§  Features Summary
âœ… RAG (Retrieval-Augmented Generation)
âœ… Hybrid backend: Ollama (local) & OpenAI (cloud)
âœ… Streamlit UI + FastAPI RESTful API
âœ… Embedding with SentenceTransformers
âœ… Memory, logging, and vector caching
âœ… One-command Docker deployment

âœ¨ Author
Lang Ju (AI Engineer)
GitHub: langju | LinkedIn: langju
